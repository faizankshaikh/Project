{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pylab\n",
    "import random\n",
    "from random import randint, uniform\n",
    "from skimage.util import crop\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "from lasagne import layers\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from lasagne import updates\n",
    "import lasagne as nn\n",
    "from theano.tensor.nnet import softmax\n",
    "from scipy.misc import imread, imresize\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "repo_location = '/workspace/.project/project/'\n",
    "data_root = os.path.join(os.path.expanduser('~') + repo_location + 'datasets/')\n",
    "script_root = os.path.join(os.path.expanduser('~') + repo_location + 'scripts/')\n",
    "model_root = os.path.join(os.path.expanduser('~') + repo_location + 'models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded icdar03\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_soup = bs(open(data_root + 'icdar03/train/char/char.xml').read(), 'lxml-xml')\n",
    "test_soup = bs(open(data_root + 'icdar03/test/char/char.xml').read(), 'lxml-xml')\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for image in train_soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/train/char/' + image['file'])\n",
    "        X_train.append(img)\n",
    "        y_train.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for image in test_soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/test/char/' + image['file'])\n",
    "        X_test.append(img)\n",
    "        y_test.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "data_train = pd.DataFrame({'image' : X_train, 'label' : y_train})\n",
    "data_test = pd.DataFrame({'image' : X_test, 'label' : y_test})\n",
    "\n",
    "print 'Loaded icdar03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icdar03 reshaped and grayscaled\n"
     ]
    }
   ],
   "source": [
    "# Reshape images to 64x64 and convert to grayscale\n",
    "data_train_x = np.zeros((data_train['image'].count(), 1, 64, 64))\n",
    "data_train_y = data_train['label'].values\n",
    "data_test_x = np.zeros((data_test['image'].count(), 1, 64, 64))\n",
    "data_test_y = data_test['label'].values\n",
    "\n",
    "for idx, img in enumerate(data_train['image']):\n",
    "    img = imresize(img, (64, 64))\n",
    "    if len(img.shape) == 3:\n",
    "        data_train_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data_train_x[idx, ...] = img\n",
    "        \n",
    "for idx, img in enumerate(data_test['image']):\n",
    "    img = imresize(img, (64, 64))\n",
    "    if len(img.shape) == 3:\n",
    "        data_test_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data_test_x[idx, ...] = img\n",
    "        \n",
    "data_train_x = data_train_x.astype('float32')\n",
    "data_test_x = data_test_x.astype('float32')\n",
    "print 'icdar03 reshaped and grayscaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize by MuSigma\n",
    "data_train_x /= data_train_x.std(axis = None)\n",
    "data_train_x -= data_train_x.mean()\n",
    "\n",
    "data_test_x /= data_test_x.std(axis = None)\n",
    "data_test_x -= data_test_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6185, 1, 64, 64) (6185,) (5430, 1, 64, 64) (5430,)\n"
     ]
    }
   ],
   "source": [
    "print data_train_x.shape, data_train_y.shape, data_test_x.shape, data_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransIterator(BatchIterator):\n",
    "    def fast_warp(self, img, tf, output_shape, mode='nearest'):\n",
    "        return transform._warps_cy._warp_fast(img, tf.params, output_shape=output_shape, mode=mode)\n",
    "    \n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(TransIterator, self).transform(Xb, yb)\n",
    "        \n",
    "        Xb_aug = np.empty(shape = (Xb.shape[0], 1, 64, 64), dtype = 'float32')\n",
    "        yb_aug = yb\n",
    "\n",
    "        # random rotations betweein -5 and 5 degrees\n",
    "        dorotate = randint(-5,5)\n",
    "\n",
    "        # random translations\n",
    "        trans_1 = randint(-10,10)\n",
    "        trans_2 = randint(-10,10)\n",
    "\n",
    "        # random zooms\n",
    "        zoom = uniform(0.8, 1.2)\n",
    "\n",
    "        # shearing\n",
    "        shear_deg = uniform(-10, 10)\n",
    "\n",
    "        # set the transform parameters for skimage.transform.warp\n",
    "        # have to shift to center and then shift back after transformation otherwise\n",
    "        # rotations will make image go out of frame\n",
    "        center_shift   = np.array((64, 64)) / 2. - 0.5\n",
    "        tform_center   = transform.SimilarityTransform(translation=-center_shift)\n",
    "        tform_uncenter = transform.SimilarityTransform(translation=center_shift)\n",
    "\n",
    "        tform_aug = transform.AffineTransform(rotation = np.deg2rad(dorotate),\n",
    "                                              scale =(1/zoom, 1/zoom),\n",
    "                                              shear = np.deg2rad(shear_deg),\n",
    "                                              translation = (trans_1, trans_2))\n",
    "\n",
    "        tform = tform_center + tform_aug + tform_uncenter\n",
    "        \n",
    "        for j in range(Xb.shape[0]):\n",
    "            Xb_aug[j][0] = self.fast_warp(Xb[j][0], tform,\n",
    "                                          output_shape = (64, 64))\n",
    "\n",
    "        return Xb_aug, yb_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting nn \n",
    "net = NeuralNet(\n",
    "    layers = [\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('dropout4', layers.DropoutLayer),\n",
    "        ('conv5', layers.Conv2DLayer),\n",
    "        ('conv6', layers.Conv2DLayer),\n",
    "        ('pool7', layers.MaxPool2DLayer),\n",
    "        ('dropout8', layers.DropoutLayer),\n",
    "        ('hidden13', layers.DenseLayer),\n",
    "        ('dropout14', layers.DropoutLayer),\n",
    "        ('hidden15', layers.DenseLayer),\n",
    "        ('dropout16', layers.DropoutLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "    ],\n",
    "\n",
    "    input_shape = (None, 1, 64, 64),\n",
    "    conv1_num_filters = 128, conv1_filter_size = (3, 3),\n",
    "    conv2_num_filters = 128, conv2_filter_size = (3, 3),\n",
    "    pool3_pool_size = (2, 2),\n",
    "    dropout4_p = 0.2,\n",
    "    conv5_num_filters = 256, conv5_filter_size = (3, 3),\n",
    "    conv6_num_filters = 256, conv6_filter_size = (3, 3),\n",
    "    pool7_pool_size = (2, 2),\n",
    "    dropout8_p = 0.2,\n",
    "    hidden13_num_units = 1024,\n",
    "    dropout14_p = 0.5,\n",
    "    hidden15_num_units = 1024,\n",
    "    dropout16_p = 0.5,\n",
    "    output_num_units = 75, output_nonlinearity = softmax,\n",
    "\n",
    "    batch_iterator_train = TransIterator(batch_size = 256),\n",
    "    batch_iterator_test = BatchIterator(batch_size = 256),\n",
    "\n",
    "    update = updates.adam,\n",
    "\n",
    "    use_label_encoder = True,\n",
    "    regression = False,\n",
    "    max_epochs = 300,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 46463947 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  ---------  ---------\n",
      "  0  input      1x64x64\n",
      "  1  conv1      128x62x62\n",
      "  2  conv2      128x60x60\n",
      "  3  pool3      128x30x30\n",
      "  4  dropout4   128x30x30\n",
      "  5  conv5      256x28x28\n",
      "  6  conv6      256x26x26\n",
      "  7  pool7      256x13x13\n",
      "  8  dropout8   256x13x13\n",
      "  9  hidden13   1024\n",
      " 10  dropout14  1024\n",
      " 11  hidden15   1024\n",
      " 12  dropout16  1024\n",
      " 13  output     75\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m4.07641\u001b[0m       \u001b[32m3.84068\u001b[0m      1.06138      0.05156  51.14s\n",
      "      2       \u001b[36m3.80502\u001b[0m       \u001b[32m3.77123\u001b[0m      1.00896      0.06221  52.71s\n",
      "      3       \u001b[36m3.72778\u001b[0m       \u001b[32m3.76573\u001b[0m      0.98992      0.06651  52.60s\n",
      "      4       \u001b[36m3.60068\u001b[0m       \u001b[32m3.55215\u001b[0m      1.01366      0.10490  52.67s\n",
      "      5       \u001b[36m3.37870\u001b[0m       \u001b[32m3.20961\u001b[0m      1.05268      0.25244  52.75s\n",
      "      6       \u001b[36m3.31460\u001b[0m       \u001b[32m3.11665\u001b[0m      1.06351      0.29743  52.54s\n",
      "      7       \u001b[36m3.13720\u001b[0m       3.45049      0.90920      0.26071  52.64s\n",
      "      8       \u001b[36m3.12747\u001b[0m       \u001b[32m2.93692\u001b[0m      1.06488      0.34820  52.23s\n",
      "      9       \u001b[36m2.89936\u001b[0m       \u001b[32m2.76368\u001b[0m      1.04909      0.37906  52.45s\n",
      "     10       \u001b[36m2.80602\u001b[0m       2.76480      1.01491      0.39823  52.71s\n",
      "     11       \u001b[36m2.73201\u001b[0m       \u001b[32m2.55306\u001b[0m      1.07009      0.43058  52.39s\n",
      "     12       \u001b[36m2.49198\u001b[0m       \u001b[32m2.20826\u001b[0m      1.12848      0.52925  52.34s\n",
      "     13       \u001b[36m2.45399\u001b[0m       \u001b[32m2.17939\u001b[0m      1.12600      0.53540  52.31s\n",
      "     14       \u001b[36m2.29532\u001b[0m       2.18743      1.04932      0.50444  51.97s\n",
      "     15       \u001b[36m2.16068\u001b[0m       \u001b[32m1.90916\u001b[0m      1.13175      0.58969  52.27s\n",
      "     16       \u001b[36m2.05779\u001b[0m       \u001b[32m1.81029\u001b[0m      1.13672      0.60912  52.37s\n",
      "     17       \u001b[36m2.00595\u001b[0m       \u001b[32m1.76699\u001b[0m      1.13524      0.58976  52.28s\n",
      "     18       \u001b[36m1.89767\u001b[0m       \u001b[32m1.65010\u001b[0m      1.15003      0.64004  52.21s\n",
      "     19       \u001b[36m1.76604\u001b[0m       1.74187      1.01387      0.58767  52.13s\n",
      "     20       1.82329       \u001b[32m1.55659\u001b[0m      1.17134      0.64707  52.13s\n",
      "     21       \u001b[36m1.53584\u001b[0m       \u001b[32m1.38197\u001b[0m      1.11134      0.69298  52.32s\n",
      "     22       1.69129       1.51963      1.11297      0.65890  52.50s\n",
      "     23       \u001b[36m1.51504\u001b[0m       1.39901      1.08293      0.68024  52.30s\n",
      "     24       \u001b[36m1.47129\u001b[0m       \u001b[32m1.30035\u001b[0m      1.13145      0.68836  52.31s\n",
      "     25       1.57948       1.46135      1.08083      0.66046  52.58s\n",
      "     26       \u001b[36m1.37634\u001b[0m       \u001b[32m1.19765\u001b[0m      1.14920      0.71425  52.44s\n",
      "     27       \u001b[36m1.30675\u001b[0m       1.25757      1.03910      0.71191  52.60s\n",
      "     28       \u001b[36m1.30113\u001b[0m       1.21337      1.07232      0.71535  52.56s\n",
      "     29       \u001b[36m1.27469\u001b[0m       \u001b[32m1.19678\u001b[0m      1.06510      0.70658  52.38s\n",
      "     30       1.36741       \u001b[32m1.16384\u001b[0m      1.17491      0.73030  52.31s\n",
      "     31       1.39381       1.27761      1.09095      0.70647  52.48s\n",
      "     32       \u001b[36m1.25788\u001b[0m       1.18331      1.06301      0.71950  52.81s\n",
      "     33       \u001b[36m1.13445\u001b[0m       1.20560      0.94098      0.72976  52.25s\n",
      "     34       1.27243       \u001b[32m1.12350\u001b[0m      1.13256      0.74084  52.18s\n",
      "     35       1.31965       \u001b[32m1.08498\u001b[0m      1.21629      0.75490  52.18s\n",
      "     36       1.22849       1.08676      1.13041      0.74681  52.26s\n",
      "     37       1.17733       \u001b[32m1.06411\u001b[0m      1.10640      0.76452  52.16s\n",
      "     38       1.18346       1.12353      1.05334      0.72050  52.54s\n",
      "     39       \u001b[36m1.03584\u001b[0m       \u001b[32m1.04976\u001b[0m      0.98674      0.75735  52.36s\n",
      "     40       1.05863       1.09693      0.96508      0.74862  52.08s\n",
      "     41       1.03970       \u001b[32m0.99575\u001b[0m      1.04414      0.76452  52.24s\n",
      "     42       \u001b[36m1.03475\u001b[0m       1.00705      1.02750      0.76527  52.16s\n",
      "     43       1.16632       1.02110      1.14222      0.74290  52.05s\n",
      "     44       1.04161       1.08446      0.96049      0.74276  52.24s\n",
      "     45       1.15210       1.09951      1.04783      0.73125  52.36s\n",
      "     46       1.16604       1.07109      1.08865      0.74560  52.26s\n",
      "     47       \u001b[36m0.98135\u001b[0m       \u001b[32m0.97855\u001b[0m      1.00286      0.75827  51.96s\n",
      "     48       \u001b[36m0.96185\u001b[0m       1.00219      0.95975      0.75739  52.61s\n",
      "     49       1.00955       1.05180      0.95984      0.74464  52.58s\n",
      "     50       \u001b[36m0.95429\u001b[0m       \u001b[32m0.96262\u001b[0m      0.99135      0.75834  52.25s\n",
      "     51       0.97467       0.99312      0.98142      0.75810  52.12s\n",
      "     52       0.97067       \u001b[32m0.95575\u001b[0m      1.01561      0.76470  52.25s\n",
      "     53       \u001b[36m0.87790\u001b[0m       1.04621      0.83912      0.74872  52.20s\n",
      "     54       \u001b[36m0.83223\u001b[0m       \u001b[32m0.95058\u001b[0m      0.87550      0.76537  52.81s\n",
      "     55       0.93417       0.96337      0.96969      0.77734  52.37s\n",
      "     56       0.89805       0.97126      0.92463      0.77027  52.24s\n",
      "     57       0.96655       0.98855      0.97775      0.76810  52.82s\n",
      "     58       0.86073       \u001b[32m0.92240\u001b[0m      0.93314      0.78341  52.67s\n",
      "     59       0.88325       0.94583      0.93383      0.77638  52.64s\n",
      "     60       0.83234       \u001b[32m0.90616\u001b[0m      0.91854      0.78518  52.45s\n",
      "     61       0.88828       0.91719      0.96848      0.78526  52.40s\n",
      "     62       0.83693       0.93152      0.89846      0.76594  52.59s\n",
      "     63       0.88071       0.95990      0.91750      0.77758  52.49s\n",
      "     64       \u001b[36m0.81496\u001b[0m       0.98427      0.82799      0.75451  52.58s\n",
      "     65       0.90214       0.99817      0.90380      0.75121  52.01s\n",
      "     66       \u001b[36m0.80883\u001b[0m       0.90705      0.89171      0.78423  52.01s\n",
      "     67       0.85216       0.99418      0.85715      0.76004  52.00s\n",
      "     68       \u001b[36m0.79842\u001b[0m       0.96609      0.82644      0.76701  51.99s\n",
      "     69       0.84410       0.93095      0.90671      0.77506  51.95s\n",
      "     70       \u001b[36m0.76225\u001b[0m       0.98362      0.77494      0.77261  51.98s\n",
      "     71       0.86340       0.96376      0.89587      0.76477  52.35s\n",
      "     72       \u001b[36m0.73604\u001b[0m       0.95531      0.77047      0.77560  52.50s\n",
      "     73       0.86951       0.99263      0.87597      0.75973  52.15s\n",
      "     74       0.76676       0.95051      0.80668      0.78067  52.81s\n",
      "     75       0.78998       0.91465      0.86369      0.78831  52.62s\n",
      "     76       0.78508       0.93686      0.83800      0.78234  52.43s\n",
      "     77       0.76143       0.95747      0.79526      0.77520  52.82s\n",
      "     78       \u001b[36m0.72015\u001b[0m       \u001b[32m0.88653\u001b[0m      0.81232      0.80116  52.11s\n",
      "     79       0.81248       0.90736      0.89544      0.78430  52.41s\n",
      "     80       0.80833       \u001b[32m0.86469\u001b[0m      0.93482      0.78678  52.37s\n",
      "     81       0.77630       0.89811      0.86437      0.79012  52.49s\n",
      "     82       \u001b[36m0.65027\u001b[0m       0.87044      0.74706      0.80020  52.36s\n",
      "     83       0.70354       0.90840      0.77448      0.78937  53.39s\n",
      "     84       0.73540       0.88729      0.82881      0.79331  52.83s\n",
      "     85       0.65050       0.92933      0.69997      0.78156  52.44s\n",
      "     86       0.71132       0.89947      0.79083      0.78824  52.29s\n",
      "     87       0.71386       \u001b[32m0.86086\u001b[0m      0.82924      0.79797  52.42s\n",
      "     88       0.72244       0.90869      0.79504      0.78927  52.46s\n",
      "     89       0.79945       0.89412      0.89413      0.77958  52.26s\n",
      "     90       0.70559       0.88018      0.80164      0.79215  52.28s\n",
      "     91       0.65074       0.86625      0.75121      0.78842  52.39s\n",
      "     92       0.73738       0.88455      0.83363      0.79026  52.25s\n",
      "     93       0.70396       0.91857      0.76637      0.77588  52.39s\n",
      "     94       0.69895       0.93093      0.75081      0.78852  52.21s\n",
      "     95       \u001b[36m0.63274\u001b[0m       0.90213      0.70138      0.78536  52.59s\n",
      "     96       0.63569       0.90054      0.70590      0.79250  52.06s\n",
      "     97       \u001b[36m0.56175\u001b[0m       0.92017      0.61049      0.79019  52.02s\n",
      "     98       0.65019       0.86290      0.75349      0.79956  52.00s\n",
      "     99       0.63228       0.89000      0.71042      0.78852  52.07s\n",
      "    100       \u001b[36m0.52136\u001b[0m       0.87447      0.59620      0.80237  52.02s\n"
     ]
    }
   ],
   "source": [
    "# train nn\n",
    "#net.load_params_from(os.path.join(model_root, 'recog_for_icdar.pkl')); # or load a pretrained model!\n",
    "net.fit(data_train_x, data_train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79576427256\n"
     ]
    }
   ],
   "source": [
    "pred = net.predict(data_test_x)\n",
    "print accuracy_score(data_test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          !       0.31      0.50      0.38         8\n",
      "          \"       0.00      0.00      0.00         1\n",
      "          &       1.00      0.57      0.73         7\n",
      "          '       0.40      0.25      0.31         8\n",
      "          (       0.00      0.00      0.00         1\n",
      "          )       0.50      1.00      0.67         1\n",
      "          ,       0.00      0.00      0.00         6\n",
      "          -       0.50      0.75      0.60         4\n",
      "          .       0.38      0.55      0.44        11\n",
      "          0       1.00      0.04      0.08        46\n",
      "          1       0.76      0.48      0.59        46\n",
      "          2       0.82      0.94      0.88        49\n",
      "          3       0.71      0.59      0.65        17\n",
      "          4       0.78      0.58      0.67        24\n",
      "          5       0.77      0.34      0.48        29\n",
      "          6       0.90      0.60      0.72        15\n",
      "          7       0.50      0.30      0.37        10\n",
      "          8       1.00      0.67      0.80         6\n",
      "          9       1.00      0.20      0.33        15\n",
      "          ?       0.00      0.00      0.00         1\n",
      "          A       0.96      0.92      0.94       223\n",
      "          B       0.69      0.85      0.76        47\n",
      "          C       0.80      0.80      0.80       153\n",
      "          D       0.86      0.82      0.84        74\n",
      "          E       0.78      0.91      0.84       322\n",
      "          F       0.92      0.86      0.88        76\n",
      "          G       0.90      0.83      0.86        63\n",
      "          H       0.94      0.91      0.92        97\n",
      "          I       0.49      0.53      0.51       163\n",
      "          J       0.50      0.54      0.52        13\n",
      "          K       0.97      0.72      0.82        46\n",
      "          L       0.67      0.83      0.74       131\n",
      "          M       0.82      0.90      0.86        89\n",
      "          N       0.97      0.87      0.92       153\n",
      "          O       0.65      0.83      0.73       187\n",
      "          P       0.88      0.87      0.87        91\n",
      "          Q       0.00      0.00      0.00         4\n",
      "          R       0.91      0.85      0.88       205\n",
      "          S       0.81      0.81      0.81       229\n",
      "          T       0.91      0.81      0.86       205\n",
      "          U       0.80      0.84      0.82        92\n",
      "          V       0.79      0.73      0.76        26\n",
      "          W       0.85      0.87      0.86        39\n",
      "          X       0.76      0.84      0.80        19\n",
      "          Y       0.84      0.88      0.86        42\n",
      "          Z       0.80      0.57      0.67         7\n",
      "          a       0.87      0.82      0.84       171\n",
      "          b       0.69      0.83      0.75        24\n",
      "          c       0.86      0.63      0.73       100\n",
      "          d       0.80      0.87      0.83        54\n",
      "          e       0.91      0.88      0.89       331\n",
      "          f       0.90      0.74      0.81        47\n",
      "          g       0.55      0.84      0.67        38\n",
      "          h       0.97      0.80      0.88        86\n",
      "          i       0.77      0.86      0.81       182\n",
      "          j       0.00      0.00      0.00         4\n",
      "          k       0.69      0.94      0.79        33\n",
      "          l       0.33      0.36      0.34       105\n",
      "          m       0.91      0.76      0.83        51\n",
      "          n       0.91      0.91      0.91       162\n",
      "          o       0.78      0.71      0.74       194\n",
      "          p       0.83      0.70      0.76        56\n",
      "          q       0.00      0.00      0.00         3\n",
      "          r       0.87      0.79      0.82       177\n",
      "          s       0.69      0.90      0.78       154\n",
      "          t       0.84      0.90      0.87       173\n",
      "          u       0.71      0.79      0.75        67\n",
      "          v       0.71      0.62      0.67        24\n",
      "          w       0.54      0.79      0.64        19\n",
      "          x       0.73      0.92      0.81        12\n",
      "          y       0.77      0.81      0.79        57\n",
      "          z       0.00      0.00      0.00         2\n",
      "          Â£       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.81      0.80      0.79      5430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuda/anaconda2/envs/ff_env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print classification_report(data_test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.save_params_to(os.path.join(model_root, 'recog_for_icdar_1.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
