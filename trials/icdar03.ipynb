{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pylab\n",
    "import random\n",
    "from random import randint, uniform\n",
    "from skimage.util import crop\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "from lasagne import layers\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from lasagne import updates\n",
    "import lasagne as nn\n",
    "from theano.tensor.nnet import softmax\n",
    "from scipy.misc import imread, imresize\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "repo_location = '/workspace/.project/project/'\n",
    "data_root = os.path.join(os.path.expanduser('~') + repo_location + 'datasets/')\n",
    "script_root = os.path.join(os.path.expanduser('~') + repo_location + 'scripts/')\n",
    "model_root = os.path.join(os.path.expanduser('~') + repo_location + 'models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded icdar03\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_soup = bs(open(data_root + 'icdar03/train/char/char.xml').read(), 'lxml-xml')\n",
    "test_soup = bs(open(data_root + 'icdar03/test/char/char.xml').read(), 'lxml-xml')\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for image in train_soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/train/char/' + image['file'])\n",
    "        X_train.append(img)\n",
    "        y_train.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for image in test_soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/test/char/' + image['file'])\n",
    "        X_test.append(img)\n",
    "        y_test.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "data_train = pd.DataFrame({'image' : X_train, 'label' : y_train})\n",
    "data_test = pd.DataFrame({'image' : X_test, 'label' : y_test})\n",
    "\n",
    "# drop extra labels\n",
    "data_train = data_train.loc[~data_train['label'].isin([':', '-', '.', '\\'', '!', '(', '\"', ')', '&', '?', u'\\xa3', u'\\xc9', u'\\xd1', u'\\xe9', ','])]\n",
    "data_test = data_test.loc[~data_test['label'].isin([':', '-', '.', '\\'', '!', '(', '\"', ')', '&', '?', u'\\xa3', u'\\xc9', u'\\xd1', u'\\xe9', ','])]\n",
    "\n",
    "print 'Loaded icdar03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icdar03 reshaped and grayscaled\n"
     ]
    }
   ],
   "source": [
    "# Reshape images to 32x32 and convert to grayscale\n",
    "data_train_x = np.zeros((data_train['image'].count(), 1, 32, 32))\n",
    "data_train_y = data_train['label'].values\n",
    "data_test_x = np.zeros((data_test['image'].count(), 1, 32, 32))\n",
    "data_test_y = data_test['label'].values\n",
    "\n",
    "for idx, img in enumerate(data_train['image']):\n",
    "    img = imresize(img, (32, 32))\n",
    "    if len(img.shape) == 3:\n",
    "        data_train_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data_train_x[idx, ...] = img\n",
    "        \n",
    "for idx, img in enumerate(data_test['image']):\n",
    "    img = imresize(img, (32, 32))\n",
    "    if len(img.shape) == 3:\n",
    "        data_test_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data_test_x[idx, ...] = img\n",
    "        \n",
    "data_train_x = data_train_x.astype('float32')\n",
    "data_test_x = data_test_x.astype('float32')\n",
    "print 'icdar03 reshaped and grayscaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize by MuSigma\n",
    "data_train_x /= data_train_x.std(axis = None)\n",
    "data_train_x -= data_train_x.mean()\n",
    "\n",
    "data_test_x /= data_test_x.std(axis = None)\n",
    "data_test_x -= data_test_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6113, 1, 32, 32) (6113,) (5379, 1, 32, 32) (5379,)\n"
     ]
    }
   ],
   "source": [
    "print data_train_x.shape, data_train_y.shape, data_test_x.shape, data_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransIterator(BatchIterator):\n",
    "    def fast_warp(self, img, tf, output_shape, mode='nearest'):\n",
    "        return transform._warps_cy._warp_fast(img, tf.params, output_shape=output_shape, mode=mode)\n",
    "    \n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(TransIterator, self).transform(Xb, yb)\n",
    "        \n",
    "        Xb_aug = np.empty(shape = (Xb.shape[0], 1, 32, 32), dtype = 'float32')\n",
    "        yb_aug = yb\n",
    "\n",
    "        # random rotations betweein -5 and 5 degrees\n",
    "        dorotate = randint(-5,5)\n",
    "\n",
    "        # random translations\n",
    "        trans_1 = randint(-3,3)\n",
    "        trans_2 = randint(-3,3)\n",
    "\n",
    "        # random zooms\n",
    "        zoom = uniform(0.8, 1.2)\n",
    "\n",
    "        # shearing\n",
    "        shear_deg = uniform(-10, 10)\n",
    "\n",
    "        # set the transform parameters for skimage.transform.warp\n",
    "        # have to shift to center and then shift back after transformation otherwise\n",
    "        # rotations will make image go out of frame\n",
    "        center_shift   = np.array((32, 32)) / 2. - 0.5\n",
    "        tform_center   = transform.SimilarityTransform(translation=-center_shift)\n",
    "        tform_uncenter = transform.SimilarityTransform(translation=center_shift)\n",
    "\n",
    "        tform_aug = transform.AffineTransform(rotation = np.deg2rad(dorotate),\n",
    "                                              scale =(1/zoom, 1/zoom),\n",
    "                                              shear = np.deg2rad(shear_deg),\n",
    "                                              translation = (trans_1, trans_2))\n",
    "\n",
    "        tform = tform_center + tform_aug + tform_uncenter\n",
    "        \n",
    "        for j in range(Xb.shape[0]):\n",
    "            Xb_aug[j][0] = self.fast_warp(Xb[j][0], tform,\n",
    "                                          output_shape = (32, 32))\n",
    "\n",
    "        return Xb_aug, yb_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting nn \n",
    "net = NeuralNet(\n",
    "    layers = [\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('dropout4', layers.DropoutLayer),\n",
    "        ('conv5', layers.Conv2DLayer),\n",
    "        ('conv6', layers.Conv2DLayer),\n",
    "        ('pool7', layers.MaxPool2DLayer),\n",
    "        ('dropout8', layers.DropoutLayer),\n",
    "        ('conv9', layers.Conv2DLayer),\n",
    "        ('conv10', layers.Conv2DLayer),\n",
    "        ('dropout12', layers.DropoutLayer),\n",
    "        ('hidden13', layers.DenseLayer),\n",
    "        ('dropout14', layers.DropoutLayer),\n",
    "        ('hidden15', layers.DenseLayer),\n",
    "        ('dropout16', layers.DropoutLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "    ],\n",
    "\n",
    "    input_shape = (None, 1, 32, 32),\n",
    "    conv1_num_filters = 128, conv1_filter_size = (3, 3),\n",
    "    conv2_num_filters = 128, conv2_filter_size = (3, 3),\n",
    "    pool3_pool_size = (2, 2),\n",
    "    dropout4_p = 0,\n",
    "    conv5_num_filters = 256, conv5_filter_size = (3, 3),\n",
    "    conv6_num_filters = 256, conv6_filter_size = (3, 3),\n",
    "    pool7_pool_size = (2, 2),\n",
    "    dropout8_p = 0.2,\n",
    "    conv9_num_filters = 512, conv9_filter_size = (3, 3),\n",
    "    conv10_num_filters = 512, conv10_filter_size = (3, 3),\n",
    "    dropout12_p = 0.2,\n",
    "    hidden13_num_units = 1024,\n",
    "    dropout14_p = 0.5,\n",
    "    hidden15_num_units = 1024,\n",
    "    dropout16_p = 0.5,\n",
    "    output_num_units = 62, output_nonlinearity = softmax,\n",
    "\n",
    "    batch_iterator_train = TransIterator(batch_size = 2500),\n",
    "    batch_iterator_test = BatchIterator(batch_size = 2500),\n",
    "\n",
    "    update = updates.adam,\n",
    "\n",
    "    use_label_encoder = True,\n",
    "    regression = False,\n",
    "    max_epochs = 300,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 6212542 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  ---------  ---------\n",
      "  0  input      1x32x32\n",
      "  1  conv1      128x30x30\n",
      "  2  conv2      128x28x28\n",
      "  3  pool3      128x14x14\n",
      "  4  dropout4   128x14x14\n",
      "  5  conv5      256x12x12\n",
      "  6  conv6      256x10x10\n",
      "  7  pool7      256x5x5\n",
      "  8  dropout8   256x5x5\n",
      "  9  conv9      512x3x3\n",
      " 10  conv10     512x1x1\n",
      " 11  dropout12  512x1x1\n",
      " 12  hidden13   1024\n",
      " 13  dropout14  1024\n",
      " 14  hidden15   1024\n",
      " 15  dropout16  1024\n",
      " 16  output     62\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m4.04503\u001b[0m       \u001b[32m7.41551\u001b[0m      0.54548      0.05297  11.51s\n",
      "      2       7.08244       \u001b[32m4.07214\u001b[0m      1.73924      0.04414  11.31s\n",
      "      3       4.07716       4.11162      0.99162      0.03852  11.44s\n",
      "      4       4.10915       4.10749      1.00041      0.03451  12.05s\n",
      "      5       4.10416       4.09874      1.00132      0.03371  12.15s\n",
      "      6       4.09411       4.08424      1.00242      0.03371  12.03s\n",
      "      7       4.07378       \u001b[32m4.04499\u001b[0m      1.00712      0.03772  11.82s\n",
      "      8       \u001b[36m4.00858\u001b[0m       \u001b[32m3.93426\u001b[0m      1.01889      0.03772  11.97s\n",
      "      9       \u001b[36m3.95636\u001b[0m       \u001b[32m3.88758\u001b[0m      1.01769      0.03772  11.88s\n",
      "     10       \u001b[36m3.88203\u001b[0m       \u001b[32m3.86756\u001b[0m      1.00374      0.03772  11.93s\n",
      "     11       \u001b[36m3.84008\u001b[0m       \u001b[32m3.80057\u001b[0m      1.01040      0.03772  11.81s\n",
      "     12       \u001b[36m3.78305\u001b[0m       \u001b[32m3.75201\u001b[0m      1.00827      0.06260  11.90s\n",
      "     13       \u001b[36m3.75447\u001b[0m       \u001b[32m3.73462\u001b[0m      1.00531      0.06260  11.90s\n",
      "     14       \u001b[36m3.72231\u001b[0m       3.73639      0.99623      0.05698  11.85s\n",
      "     15       3.72956       \u001b[32m3.73235\u001b[0m      0.99925      0.05297  11.75s\n",
      "     16       3.72519       \u001b[32m3.72379\u001b[0m      1.00038      0.05297  11.77s\n",
      "     17       \u001b[36m3.71664\u001b[0m       \u001b[32m3.71741\u001b[0m      0.99979      0.05297  11.74s\n",
      "     18       \u001b[36m3.71172\u001b[0m       \u001b[32m3.71292\u001b[0m      0.99968      0.06260  11.77s\n",
      "     19       \u001b[36m3.71076\u001b[0m       \u001b[32m3.71062\u001b[0m      1.00004      0.06260  11.75s\n",
      "     20       \u001b[36m3.70792\u001b[0m       \u001b[32m3.70804\u001b[0m      0.99997      0.06260  11.70s\n",
      "     21       \u001b[36m3.69835\u001b[0m       \u001b[32m3.70619\u001b[0m      0.99789      0.06260  11.73s\n",
      "     22       3.70490       \u001b[32m3.70394\u001b[0m      1.00026      0.06260  11.72s\n",
      "     23       \u001b[36m3.69821\u001b[0m       \u001b[32m3.70114\u001b[0m      0.99921      0.06260  11.71s\n",
      "     24       \u001b[36m3.68914\u001b[0m       \u001b[32m3.69561\u001b[0m      0.99825      0.06260  11.68s\n",
      "     25       \u001b[36m3.68341\u001b[0m       \u001b[32m3.68779\u001b[0m      0.99881      0.06260  11.74s\n",
      "     26       \u001b[36m3.68168\u001b[0m       \u001b[32m3.67090\u001b[0m      1.00294      0.06260  11.67s\n",
      "     27       \u001b[36m3.66363\u001b[0m       3.69657      0.99109      0.06260  11.72s\n",
      "     28       3.66750       \u001b[32m3.65483\u001b[0m      1.00347      0.06260  11.72s\n",
      "     29       \u001b[36m3.65290\u001b[0m       3.70197      0.98675      0.06260  11.70s\n",
      "     30       3.65964       \u001b[32m3.65344\u001b[0m      1.00170      0.06260  11.67s\n",
      "     31       3.65292       \u001b[32m3.64515\u001b[0m      1.00213      0.06260  11.68s\n",
      "     32       \u001b[36m3.61994\u001b[0m       3.65864      0.98942      0.06260  11.72s\n",
      "     33       3.63008       \u001b[32m3.63145\u001b[0m      0.99962      0.06260  11.66s\n",
      "     34       \u001b[36m3.61619\u001b[0m       \u001b[32m3.61433\u001b[0m      1.00051      0.06501  11.73s\n",
      "     35       \u001b[36m3.58396\u001b[0m       \u001b[32m3.59557\u001b[0m      0.99677      0.07303  11.66s\n",
      "     36       \u001b[36m3.55561\u001b[0m       \u001b[32m3.58645\u001b[0m      0.99140      0.07544  11.68s\n",
      "     37       3.56118       3.62634      0.98203      0.07865  11.67s\n",
      "     38       \u001b[36m3.53921\u001b[0m       \u001b[32m3.52197\u001b[0m      1.00489      0.10353  11.72s\n",
      "     39       3.55890       3.54908      1.00277      0.09631  11.78s\n",
      "     40       \u001b[36m3.48378\u001b[0m       3.59596      0.96880      0.08186  11.75s\n",
      "     41       \u001b[36m3.46632\u001b[0m       \u001b[32m3.49559\u001b[0m      0.99163      0.10433  11.69s\n",
      "     42       \u001b[36m3.40489\u001b[0m       \u001b[32m3.46346\u001b[0m      0.98309      0.10273  11.69s\n",
      "     43       \u001b[36m3.37448\u001b[0m       \u001b[32m3.41139\u001b[0m      0.98918      0.10915  11.68s\n",
      "     44       3.39033       3.46237      0.97919      0.10112  11.64s\n",
      "     45       \u001b[36m3.35403\u001b[0m       3.53046      0.95003      0.08989  11.74s\n",
      "     46       3.38270       \u001b[32m3.36600\u001b[0m      1.00496      0.12039  11.65s\n",
      "     47       \u001b[36m3.31257\u001b[0m       3.39718      0.97509      0.11477  11.65s\n",
      "     48       \u001b[36m3.28243\u001b[0m       \u001b[32m3.28286\u001b[0m      0.99987      0.11878  11.73s\n",
      "     49       3.47624       3.60721      0.96369      0.08989  11.69s\n",
      "     50       3.44439       3.42130      1.00675      0.10273  11.69s\n",
      "     51       3.33390       3.36523      0.99069      0.11236  11.63s\n",
      "     52       3.37603       3.31043      1.01982      0.11958  11.64s\n",
      "     53       \u001b[36m3.26543\u001b[0m       3.28684      0.99349      0.14446  11.68s\n",
      "     54       \u001b[36m3.17474\u001b[0m       3.32095      0.95597      0.12921  11.69s\n",
      "     55       3.20453       \u001b[32m3.21146\u001b[0m      0.99784      0.14928  11.67s\n",
      "     56       \u001b[36m3.14901\u001b[0m       3.21211      0.98036      0.14205  11.67s\n",
      "     57       3.18862       \u001b[32m3.16910\u001b[0m      1.00616      0.14848  11.68s\n",
      "     58       3.24980       \u001b[32m3.15594\u001b[0m      1.02974      0.14125  11.68s\n",
      "     59       3.16928       3.17074      0.99954      0.13162  11.66s\n",
      "     60       3.15277       3.27824      0.96172      0.12440  11.69s\n",
      "     61       3.19234       3.17319      1.00604      0.13644  11.69s\n",
      "     62       \u001b[36m3.09394\u001b[0m       \u001b[32m3.06685\u001b[0m      1.00884      0.16934  11.65s\n",
      "     63       \u001b[36m3.07234\u001b[0m       3.22542      0.95254      0.15811  11.69s\n",
      "     64       3.14440       \u001b[32m3.01172\u001b[0m      1.04405      0.18299  11.64s\n",
      "     65       3.09732       3.02417      1.02419      0.19984  11.69s\n",
      "     66       \u001b[36m3.06313\u001b[0m       3.02074      1.01404      0.21589  11.66s\n",
      "     67       \u001b[36m2.96018\u001b[0m       3.04931      0.97077      0.19904  11.68s\n",
      "     68       3.01851       3.04128      0.99251      0.18299  11.69s\n",
      "     69       3.07690       3.17111      0.97029      0.20225  11.87s\n",
      "     70       3.12690       \u001b[32m2.93653\u001b[0m      1.06483      0.24799  11.67s\n",
      "     71       \u001b[36m2.89110\u001b[0m       2.94091      0.98306      0.20706  11.70s\n",
      "     72       2.91704       \u001b[32m2.89372\u001b[0m      1.00806      0.22472  11.68s\n",
      "     73       2.98084       2.92030      1.02073      0.22552  11.73s\n",
      "     74       3.01015       2.91756      1.03174      0.20787  11.62s\n",
      "     75       \u001b[36m2.87625\u001b[0m       2.96479      0.97014      0.18700  11.68s\n",
      "     76       2.95064       2.96456      0.99530      0.23836  11.66s\n",
      "     77       \u001b[36m2.84684\u001b[0m       \u001b[32m2.85769\u001b[0m      0.99620      0.23355  11.72s\n",
      "     78       \u001b[36m2.80724\u001b[0m       \u001b[32m2.80492\u001b[0m      1.00083      0.23997  11.68s\n",
      "     79       2.91011       3.16121      0.92057      0.21669  11.67s\n",
      "     80       2.85914       \u001b[32m2.74738\u001b[0m      1.04068      0.29695  11.94s\n",
      "     81       2.92770       2.81268      1.04089      0.24880  11.73s\n",
      "     82       \u001b[36m2.77410\u001b[0m       2.79230      0.99348      0.26565  11.69s\n",
      "     83       \u001b[36m2.69726\u001b[0m       \u001b[32m2.72691\u001b[0m      0.98913      0.27448  11.63s\n",
      "     84       2.86637       2.72927      1.05023      0.27287  11.71s\n",
      "     85       3.05545       2.75967      1.10718      0.27608  11.68s\n",
      "     86       2.77056       2.90084      0.95509      0.26726  11.68s\n",
      "     87       2.94430       2.74270      1.07350      0.30498  11.70s\n",
      "     88       2.72251       \u001b[32m2.64429\u001b[0m      1.02958      0.30257  11.71s\n",
      "     89       2.75742       \u001b[32m2.56639\u001b[0m      1.07443      0.31461  11.66s\n",
      "     90       \u001b[36m2.48539\u001b[0m       2.58230      0.96247      0.32504  11.69s\n",
      "     91       2.50443       \u001b[32m2.49590\u001b[0m      1.00342      0.34350  11.65s\n",
      "     92       \u001b[36m2.44357\u001b[0m       \u001b[32m2.45335\u001b[0m      0.99601      0.36116  11.65s\n",
      "     93       \u001b[36m2.29479\u001b[0m       2.57677      0.89057      0.34350  11.74s\n",
      "     94       2.83582       2.46936      1.14840      0.34510  11.65s\n",
      "     95       2.49946       \u001b[32m2.41700\u001b[0m      1.03412      0.38443  11.69s\n",
      "     96       2.41488       2.50057      0.96573      0.36276  11.68s\n",
      "     97       2.35119       2.43572      0.96529      0.38363  11.71s\n",
      "     98       2.55115       \u001b[32m2.37861\u001b[0m      1.07254      0.38443  11.70s\n",
      "     99       2.56835       2.47319      1.03848      0.32665  11.63s\n",
      "    100       2.57478       2.49037      1.03390      0.32103  11.72s\n",
      "    101       2.47656       2.41440      1.02575      0.37079  11.67s\n",
      "    102       2.53828       2.41065      1.05294      0.37480  11.64s\n",
      "    103       \u001b[36m2.27743\u001b[0m       2.53023      0.90009      0.35152  11.73s\n",
      "    104       2.49794       \u001b[32m2.31453\u001b[0m      1.07924      0.38202  11.71s\n",
      "    105       2.32275       2.33782      0.99355      0.40690  11.71s\n",
      "    106       2.50261       2.44576      1.02324      0.38202  11.66s\n",
      "    107       \u001b[36m2.18584\u001b[0m       \u001b[32m2.25373\u001b[0m      0.96988      0.41894  11.69s\n",
      "    108       2.25112       \u001b[32m2.22655\u001b[0m      1.01103      0.39567  11.66s\n",
      "    109       2.46773       2.26457      1.08971      0.39406  11.80s\n",
      "    110       2.25222       2.33852      0.96310      0.41091  11.71s\n",
      "    111       2.50466       \u001b[32m2.22385\u001b[0m      1.12627      0.44944  11.70s\n",
      "    112       2.23189       \u001b[32m2.19602\u001b[0m      1.01633      0.44864  11.68s\n",
      "    113       2.25550       2.24886      1.00295      0.43258  11.70s\n",
      "    114       2.32533       \u001b[32m2.17430\u001b[0m      1.06946      0.45265  11.73s\n",
      "    115       2.37817       \u001b[32m2.08900\u001b[0m      1.13842      0.47111  11.65s\n",
      "    116       \u001b[36m2.10398\u001b[0m       2.10279      1.00057      0.47271  11.71s\n",
      "    117       \u001b[36m1.99606\u001b[0m       \u001b[32m2.01343\u001b[0m      0.99137      0.46549  11.70s\n",
      "    118       2.07166       \u001b[32m2.01004\u001b[0m      1.03065      0.47352  11.71s\n",
      "    119       2.01170       \u001b[32m2.00449\u001b[0m      1.00360      0.49759  11.68s\n",
      "    120       \u001b[36m1.95923\u001b[0m       \u001b[32m1.93270\u001b[0m      1.01373      0.49438  11.69s\n",
      "    121       2.01669       \u001b[32m1.84635\u001b[0m      1.09225      0.50482  11.71s\n",
      "    122       \u001b[36m1.88267\u001b[0m       1.87279      1.00528      0.50080  11.69s\n",
      "    123       2.28432       2.21104      1.03314      0.42697  11.70s\n",
      "    124       1.97003       \u001b[32m1.78192\u001b[0m      1.10556      0.53451  11.71s\n",
      "    125       2.16018       1.83648      1.17626      0.53050  11.67s\n",
      "    126       2.16784       1.96365      1.10398      0.51043  11.67s\n",
      "    127       1.90644       1.98579      0.96004      0.49679  11.67s\n",
      "    128       1.88578       1.92187      0.98122      0.49920  11.73s\n",
      "    129       2.11383       1.83196      1.15386      0.51204  11.64s\n",
      "    130       1.93197       1.79940      1.07368      0.52408  11.69s\n",
      "    131       \u001b[36m1.66261\u001b[0m       1.84289      0.90217      0.52729  11.71s\n",
      "    132       1.67122       1.78926      0.93403      0.54173  11.63s\n",
      "    133       1.83799       1.78690      1.02859      0.52970  11.72s\n",
      "    134       1.78931       \u001b[32m1.70685\u001b[0m      1.04831      0.56501  11.74s\n",
      "    135       \u001b[36m1.54298\u001b[0m       1.75583      0.87878      0.55297  11.64s\n",
      "    136       \u001b[36m1.50500\u001b[0m       \u001b[32m1.61722\u001b[0m      0.93061      0.56661  11.69s\n",
      "    137       1.81954       \u001b[32m1.56690\u001b[0m      1.16124      0.57785  11.69s\n",
      "    138       1.67986       1.62596      1.03315      0.57544  11.69s\n",
      "    139       1.71158       1.59968      1.06995      0.58186  11.67s\n",
      "    140       1.59633       1.57272      1.01501      0.57945  11.72s\n",
      "    141       \u001b[36m1.46320\u001b[0m       \u001b[32m1.54138\u001b[0m      0.94928      0.58828  11.64s\n",
      "    142       1.55404       1.56764      0.99133      0.58266  11.72s\n",
      "    143       1.61553       \u001b[32m1.52400\u001b[0m      1.06006      0.59551  11.68s\n",
      "    144       1.82434       1.56787      1.16358      0.57865  11.70s\n",
      "    145       1.70290       1.60644      1.06004      0.57945  11.71s\n",
      "    146       1.64804       \u001b[32m1.51910\u001b[0m      1.08488      0.60032  11.70s\n",
      "    147       1.63320       1.52192      1.07312      0.61396  11.75s\n",
      "    148       1.47566       1.55090      0.95149      0.60433  11.82s\n",
      "    149       \u001b[36m1.44087\u001b[0m       \u001b[32m1.49301\u001b[0m      0.96508      0.60995  11.73s\n",
      "    150       \u001b[36m1.31809\u001b[0m       \u001b[32m1.40618\u001b[0m      0.93736      0.62520  11.67s\n",
      "    151       1.38595       \u001b[32m1.36229\u001b[0m      1.01737      0.63563  11.70s\n",
      "    152       1.34040       1.44328      0.92872      0.62761  11.70s\n",
      "    153       \u001b[36m1.31315\u001b[0m       1.48767      0.88269      0.61316  11.69s\n",
      "    154       1.44492       \u001b[32m1.32640\u001b[0m      1.08935      0.64607  11.70s\n",
      "    155       \u001b[36m1.24661\u001b[0m       \u001b[32m1.32043\u001b[0m      0.94409      0.64767  11.70s\n",
      "    156       1.34276       1.37437      0.97700      0.63563  11.71s\n",
      "    157       1.31810       1.35038      0.97610      0.63965  11.70s\n",
      "    158       1.40342       \u001b[32m1.28280\u001b[0m      1.09403      0.66372  11.74s\n",
      "    159       \u001b[36m1.17702\u001b[0m       \u001b[32m1.27003\u001b[0m      0.92677      0.67175  11.67s\n",
      "    160       \u001b[36m1.12642\u001b[0m       1.33280      0.84516      0.65088  11.70s\n",
      "    161       1.22105       1.30140      0.93826      0.66854  11.74s\n",
      "    162       1.29673       \u001b[32m1.22396\u001b[0m      1.05945      0.68218  11.69s\n",
      "    163       \u001b[36m1.08560\u001b[0m       1.28998      0.84157      0.68299  11.69s\n",
      "    164       \u001b[36m1.05049\u001b[0m       1.24293      0.84517      0.68218  11.75s\n",
      "    165       \u001b[36m0.99777\u001b[0m       \u001b[32m1.20351\u001b[0m      0.82905      0.69502  11.71s\n",
      "    166       1.17492       \u001b[32m1.16474\u001b[0m      1.00874      0.70064  11.70s\n",
      "    167       1.15085       1.18355      0.97237      0.68780  11.73s\n",
      "    168       1.03617       1.18975      0.87091      0.69262  11.70s\n",
      "    169       1.19866       1.18290      1.01333      0.69663  11.70s\n",
      "    170       1.02909       1.21264      0.84864      0.68299  11.70s\n",
      "    171       1.17034       \u001b[32m1.15355\u001b[0m      1.01455      0.71669  11.71s\n",
      "    172       \u001b[36m0.91490\u001b[0m       1.21856      0.75080      0.71108  11.75s\n",
      "    173       0.97385       1.19057      0.81797      0.71188  11.69s\n",
      "    174       \u001b[36m0.91023\u001b[0m       \u001b[32m1.14644\u001b[0m      0.79396      0.71589  11.71s\n",
      "    175       1.25933       1.16475      1.08120      0.69342  11.72s\n",
      "    176       0.91821       \u001b[32m1.13985\u001b[0m      0.80556      0.70064  11.69s\n",
      "    177       1.17851       \u001b[32m1.09410\u001b[0m      1.07715      0.73435  11.70s\n",
      "    178       0.91064       1.15604      0.78773      0.70626  11.74s\n",
      "    179       1.01255       1.13663      0.89084      0.71429  11.66s\n",
      "    180       \u001b[36m0.82228\u001b[0m       1.16001      0.70886      0.70626  11.73s\n",
      "    181       0.88561       1.12573      0.78670      0.70706  11.67s\n",
      "    182       0.88814       1.10165      0.80620      0.72953  11.69s\n",
      "    183       0.92050       1.14688      0.80261      0.72151  11.83s\n",
      "    184       \u001b[36m0.78964\u001b[0m       \u001b[32m1.08087\u001b[0m      0.73056      0.73917  11.72s\n",
      "    185       0.85518       \u001b[32m1.04471\u001b[0m      0.81858      0.74077  11.68s\n",
      "    186       1.23668       \u001b[32m1.03320\u001b[0m      1.19694      0.74559  11.69s\n",
      "    187       0.81304       1.14188      0.71202      0.73034  12.12s\n",
      "    188       0.91773       1.11635      0.82208      0.73355  12.04s\n",
      "    189       \u001b[36m0.73233\u001b[0m       \u001b[32m0.99420\u001b[0m      0.73660      0.74799  11.70s\n",
      "    190       0.84846       \u001b[32m0.98397\u001b[0m      0.86229      0.76003  11.69s\n",
      "    191       0.78090       1.02643      0.76079      0.75120  11.69s\n",
      "    192       0.84576       1.06556      0.79372      0.73836  11.75s\n",
      "    193       0.76939       1.04738      0.73459      0.74318  11.71s\n",
      "    194       0.82399       1.03426      0.79669      0.75843  11.69s\n",
      "    195       0.93395       1.15454      0.80894      0.71429  11.68s\n",
      "    196       0.92323       1.11327      0.82929      0.73034  11.72s\n",
      "    197       0.92196       1.06395      0.86655      0.72793  11.68s\n",
      "    198       0.78762       1.12014      0.70315      0.70947  11.84s\n",
      "    199       0.82182       1.15665      0.71052      0.71509  11.71s\n",
      "    200       0.81641       1.06810      0.76436      0.74398  11.72s\n",
      "    201       0.86683       1.00593      0.86172      0.75762  11.78s\n",
      "    202       0.76623       1.01133      0.75765      0.76244  11.72s\n",
      "    203       1.03992       1.00195      1.03789      0.74478  11.69s\n",
      "    204       0.92118       1.05610      0.87224      0.73997  11.74s\n",
      "    205       \u001b[36m0.70249\u001b[0m       1.02064      0.68829      0.74318  11.71s\n",
      "    206       0.91728       1.02322      0.89646      0.74639  11.73s\n",
      "    207       0.77965       \u001b[32m0.98270\u001b[0m      0.79338      0.75522  11.67s\n",
      "    208       \u001b[36m0.62477\u001b[0m       1.01790      0.61378      0.74398  11.74s\n",
      "    209       0.82969       0.98321      0.84386      0.74478  11.71s\n",
      "    210       0.76368       0.98319      0.77673      0.75120  11.71s\n",
      "    211       0.68881       0.98380      0.70016      0.75361  11.74s\n",
      "    212       0.74277       \u001b[32m0.96059\u001b[0m      0.77325      0.77207  11.67s\n",
      "    213       0.63056       0.99205      0.63561      0.75682  11.72s\n",
      "    214       0.67347       \u001b[32m0.95316\u001b[0m      0.70656      0.76806  11.74s\n",
      "    215       \u001b[36m0.54928\u001b[0m       0.96596      0.56864      0.77127  11.73s\n",
      "    216       0.79111       0.96202      0.82234      0.76966  11.72s\n",
      "    217       \u001b[36m0.51387\u001b[0m       0.96189      0.53423      0.77287  11.72s\n",
      "    218       0.69158       0.99606      0.69432      0.75843  12.12s\n",
      "    219       0.83809       1.01124      0.82878      0.75522  11.86s\n",
      "    220       0.66241       0.99206      0.66771      0.75682  11.74s\n",
      "    221       0.79646       1.00928      0.78913      0.76244  11.78s\n",
      "    222       0.68669       1.00538      0.68302      0.75762  12.26s\n",
      "    223       \u001b[36m0.48679\u001b[0m       \u001b[32m0.95130\u001b[0m      0.51171      0.77849  11.74s\n",
      "    224       0.75707       0.96912      0.78120      0.76244  11.92s\n",
      "    225       0.74956       \u001b[32m0.94259\u001b[0m      0.79521      0.78170  11.73s\n",
      "    226       0.55051       0.95691      0.57531      0.77608  11.71s\n",
      "    227       0.76502       0.97915      0.78131      0.77207  11.75s\n",
      "    228       \u001b[36m0.43013\u001b[0m       0.99579      0.43195      0.77528  11.76s\n",
      "    229       0.53981       0.98020      0.55071      0.77929  11.71s\n",
      "    230       0.81236       0.94610      0.85863      0.77528  11.71s\n",
      "    231       0.62745       \u001b[32m0.93083\u001b[0m      0.67407      0.77689  11.78s\n",
      "    232       0.58102       \u001b[32m0.92030\u001b[0m      0.63134      0.77368  11.76s\n",
      "    233       0.68352       0.98185      0.69616      0.77448  11.72s\n",
      "    234       0.45707       1.03158      0.44307      0.75281  11.72s\n",
      "    235       0.52419       1.02643      0.51070      0.75602  12.60s\n",
      "    236       0.53904       1.01357      0.53183      0.77287  12.39s\n",
      "    237       0.49833       0.98843      0.50416      0.77849  12.22s\n",
      "    238       0.47096       0.97207      0.48449      0.78491  12.23s\n",
      "    239       \u001b[36m0.40935\u001b[0m       0.92799      0.44112      0.78892  11.73s\n",
      "    240       0.44031       0.93915      0.46884      0.78571  11.77s\n",
      "    241       0.53950       0.94814      0.56901      0.78411  11.72s\n",
      "    242       0.68572       0.94341      0.72686      0.77368  11.81s\n",
      "    243       0.48933       0.93404      0.52389      0.78090  11.95s\n",
      "    244       0.66351       0.92843      0.71466      0.78090  11.71s\n",
      "    245       0.51465       0.94098      0.54693      0.77368  11.87s\n",
      "    246       0.46294       0.94254      0.49116      0.78090  11.77s\n",
      "    247       0.69125       0.94383      0.73238      0.77528  11.91s\n",
      "    248       0.43457       \u001b[32m0.90945\u001b[0m      0.47783      0.79133  12.03s\n",
      "    249       0.41143       \u001b[32m0.88149\u001b[0m      0.46675      0.80257  11.80s\n",
      "    250       0.76860       0.94523      0.81313      0.78491  11.92s\n",
      "    251       0.42616       1.00727      0.42308      0.76806  11.89s\n",
      "    252       0.47450       0.97882      0.48476      0.77528  11.70s\n",
      "    253       0.58077       0.97691      0.59449      0.77849  11.81s\n",
      "    254       0.65611       0.96891      0.67717      0.77608  11.89s\n",
      "    255       0.47686       1.05626      0.45146      0.76164  11.80s\n",
      "    256       0.53437       0.92723      0.57631      0.79294  11.71s\n",
      "    257       0.52025       0.89951      0.57837      0.79053  11.74s\n",
      "    258       0.53109       0.90094      0.58948      0.78491  11.72s\n",
      "    259       0.54042       0.91913      0.58797      0.78571  11.77s\n",
      "    260       \u001b[36m0.37278\u001b[0m       0.94430      0.39476      0.78090  11.72s\n",
      "    261       0.43675       0.94378      0.46276      0.79053  11.71s\n",
      "    262       0.65980       0.93891      0.70273      0.79133  11.74s\n",
      "    263       0.43272       0.95887      0.45128      0.78250  11.71s\n",
      "    264       0.42807       0.99059      0.43214      0.78250  11.72s\n",
      "    265       0.55037       0.95623      0.57556      0.78732  11.83s\n",
      "    266       0.64195       0.93490      0.68666      0.79294  11.88s\n",
      "    267       0.75077       0.97258      0.77194      0.77849  11.75s\n",
      "    268       0.43470       1.00519      0.43246      0.76645  11.95s\n",
      "    269       0.82095       0.90461      0.90752      0.77287  12.11s\n",
      "    270       0.42747       0.91203      0.46871      0.78010  12.06s\n",
      "    271       0.44065       0.95425      0.46178      0.78090  11.70s\n",
      "    272       0.42464       1.03393      0.41071      0.77127  11.74s\n",
      "    273       0.38701       1.03321      0.37457      0.77287  11.76s\n",
      "    274       \u001b[36m0.30239\u001b[0m       0.98203      0.30793      0.78732  11.69s\n",
      "    275       0.33698       0.93330      0.36107      0.79775  11.69s\n",
      "    276       0.40898       0.89517      0.45688      0.80177  11.72s\n",
      "    277       0.42971       0.89673      0.47920      0.80096  11.75s\n",
      "    278       0.31795       0.96436      0.32970      0.78250  11.71s\n",
      "    279       0.30291       0.99625      0.30405      0.77287  11.71s\n",
      "    280       0.44275       0.94393      0.46905      0.79374  11.84s\n",
      "    281       0.40932       0.97839      0.41836      0.78331  11.90s\n",
      "    282       \u001b[36m0.28797\u001b[0m       1.01548      0.28358      0.77769  11.72s\n",
      "    283       0.66815       0.95428      0.70016      0.79133  11.72s\n",
      "    284       0.36275       1.02133      0.35517      0.78411  11.75s\n",
      "    285       0.47168       0.94640      0.49839      0.79133  11.83s\n",
      "    286       0.34514       0.97923      0.35246      0.77689  11.78s\n",
      "    287       0.44190       0.94466      0.46778      0.78331  11.67s\n",
      "    288       0.61796       0.91066      0.67858      0.78892  11.74s\n",
      "    289       0.30392       0.95556      0.31805      0.78090  11.73s\n",
      "    290       0.39198       1.00088      0.39164      0.78491  11.74s\n",
      "    291       0.38609       1.03430      0.37328      0.78732  11.69s\n",
      "    292       0.34916       0.99642      0.35041      0.78010  11.70s\n",
      "    293       0.29716       1.01436      0.29295      0.78411  11.70s\n",
      "    294       0.39166       1.00873      0.38827      0.78331  11.70s\n",
      "    295       0.34293       1.02439      0.33477      0.77608  11.73s\n",
      "    296       0.66673       0.91796      0.72632      0.80177  11.71s\n",
      "    297       0.34744       0.91600      0.37930      0.78973  11.71s\n",
      "    298       0.48278       0.92394      0.52252      0.80096  11.74s\n",
      "    299       0.44053       0.94041      0.46844      0.78812  11.73s\n",
      "    300       0.54041       0.92978      0.58122      0.79454  11.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuda/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "# train nn\n",
    "#net.load_params_from(os.path.join(model_root, 'recog_for_icdar.pkl')); # or load a pretrained model!\n",
    "net.fit(data_train_x, data_train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793084216397\n"
     ]
    }
   ],
   "source": [
    "pred = net.predict(data_test_x)\n",
    "print accuracy_score(data_test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.04      0.08        46\n",
      "          1       0.74      0.63      0.68        46\n",
      "          2       0.87      0.96      0.91        49\n",
      "          3       0.86      0.71      0.77        17\n",
      "          4       0.90      0.75      0.82        24\n",
      "          5       0.79      0.38      0.51        29\n",
      "          6       1.00      0.60      0.75        15\n",
      "          7       0.56      0.50      0.53        10\n",
      "          8       0.57      0.67      0.62         6\n",
      "          9       0.71      0.33      0.45        15\n",
      "          A       0.95      0.86      0.90       223\n",
      "          B       0.76      0.81      0.78        47\n",
      "          C       0.89      0.75      0.81       153\n",
      "          D       0.74      0.85      0.79        74\n",
      "          E       0.87      0.90      0.89       322\n",
      "          F       0.90      0.82      0.86        76\n",
      "          G       0.84      0.90      0.87        63\n",
      "          H       0.91      0.89      0.90        97\n",
      "          I       0.50      0.64      0.57       163\n",
      "          J       0.57      0.62      0.59        13\n",
      "          K       1.00      0.72      0.84        46\n",
      "          L       0.77      0.86      0.81       131\n",
      "          M       0.82      0.84      0.83        89\n",
      "          N       0.99      0.86      0.92       153\n",
      "          O       0.65      0.76      0.70       187\n",
      "          P       0.91      0.87      0.89        91\n",
      "          Q       0.00      0.00      0.00         4\n",
      "          R       0.87      0.88      0.88       205\n",
      "          S       0.85      0.78      0.81       229\n",
      "          T       0.90      0.78      0.83       205\n",
      "          U       0.86      0.74      0.80        92\n",
      "          V       0.74      0.77      0.75        26\n",
      "          W       0.73      0.85      0.79        39\n",
      "          X       0.94      0.89      0.92        19\n",
      "          Y       0.95      0.86      0.90        42\n",
      "          Z       0.50      0.14      0.22         7\n",
      "          a       0.86      0.84      0.85       171\n",
      "          b       0.65      0.83      0.73        24\n",
      "          c       0.78      0.63      0.70       100\n",
      "          d       0.75      0.78      0.76        54\n",
      "          e       0.83      0.91      0.87       331\n",
      "          f       0.86      0.77      0.81        47\n",
      "          g       0.50      0.74      0.60        38\n",
      "          h       0.89      0.77      0.82        86\n",
      "          i       0.71      0.83      0.77       182\n",
      "          j       0.00      0.00      0.00         4\n",
      "          k       0.73      0.82      0.77        33\n",
      "          l       0.29      0.24      0.26       105\n",
      "          m       0.81      0.84      0.83        51\n",
      "          n       0.83      0.91      0.87       162\n",
      "          o       0.69      0.73      0.71       194\n",
      "          p       0.80      0.66      0.73        56\n",
      "          q       0.00      0.00      0.00         3\n",
      "          r       0.88      0.78      0.83       177\n",
      "          s       0.64      0.92      0.75       154\n",
      "          t       0.87      0.91      0.89       173\n",
      "          u       0.66      0.82      0.73        67\n",
      "          v       0.62      0.67      0.64        24\n",
      "          w       0.58      0.74      0.65        19\n",
      "          x       0.75      0.75      0.75        12\n",
      "          y       0.77      0.75      0.76        57\n",
      "          z       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.80      0.79      0.79      5379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuda/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print classification_report(data_test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.save_params_to(os.path.join(model_root, 'recog_for_icdar.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
