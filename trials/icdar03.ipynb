{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pylab\n",
    "import random\n",
    "from random import randint, uniform\n",
    "from skimage.util import crop\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "from lasagne import layers\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from lasagne import updates\n",
    "import lasagne as nn\n",
    "from theano.tensor.nnet import softmax\n",
    "from scipy.misc import imread, imresize\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator, visualize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "repo_location = '/workspace/.project/project/'\n",
    "data_root = os.path.join(os.path.expanduser('~') + repo_location + 'datasets/')\n",
    "script_root = os.path.join(os.path.expanduser('~') + repo_location + 'scripts/')\n",
    "model_root = os.path.join(os.path.expanduser('~') + repo_location + 'models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded icdar03\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_soup = bs(open(data_root + 'icdar03/train/char/char.xml').read(), 'lxml-xml')\n",
    "test_soup = bs(open(data_root + 'icdar03/test/char/char.xml').read(), 'lxml-xml')\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for image in train_soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/train/char/' + image['file'])\n",
    "        X_train.append(img)\n",
    "        y_train.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for image in test_soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/test/char/' + image['file'])\n",
    "        X_test.append(img)\n",
    "        y_test.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "data_train = pd.DataFrame({'image' : X_train, 'label' : y_train})\n",
    "data_test = pd.DataFrame({'image' : X_test, 'label' : y_test})\n",
    "\n",
    "# drop extra labels\n",
    "data_train = data_train.loc[~data_train['label'].isin([':', '-', '.', '\\'', '!', '(', '\"', ')', '&', '?', u'\\xa3', u'\\xc9', u'\\xd1', u'\\xe9', ','])]\n",
    "data_test = data_test.loc[~data_test['label'].isin([':', '-', '.', '\\'', '!', '(', '\"', ')', '&', '?', u'\\xa3', u'\\xc9', u'\\xd1', u'\\xe9', ','])]\n",
    "\n",
    "print 'Loaded icdar03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icdar03 reshaped and grayscaled\n"
     ]
    }
   ],
   "source": [
    "# Reshape images to 32x32 and convert to grayscale\n",
    "data_train_x = np.zeros((data_train['image'].count(), 1, 32, 32))\n",
    "data_train_y = data_train['label'].values\n",
    "data_test_x = np.zeros((data_test['image'].count(), 1, 32, 32))\n",
    "data_test_y = data_test['label'].values\n",
    "\n",
    "for idx, img in enumerate(data_train['image']):\n",
    "    img = imresize(img, (32, 32))\n",
    "    if len(img.shape) == 3:\n",
    "        data_train_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data_train_x[idx, ...] = img\n",
    "        \n",
    "for idx, img in enumerate(data_test['image']):\n",
    "    img = imresize(img, (32, 32))\n",
    "    if len(img.shape) == 3:\n",
    "        data_test_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data_test_x[idx, ...] = img\n",
    "        \n",
    "data_train_x = data_train_x.astype('float32')\n",
    "data_test_x = data_test_x.astype('float32')\n",
    "print 'icdar03 reshaped and grayscaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize by MuSigma\n",
    "data_train_x /= data_train_x.std(axis = None)\n",
    "data_train_x -= data_train_x.mean()\n",
    "\n",
    "data_test_x /= data_test_x.std(axis = None)\n",
    "data_test_x -= data_test_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6113, 1, 32, 32) (6113,) (5379, 1, 32, 32) (5379,)\n"
     ]
    }
   ],
   "source": [
    "print data_train_x.shape, data_train_y.shape, data_test_x.shape, data_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransIterator(BatchIterator):\n",
    "    def fast_warp(self, img, tf, output_shape, mode='nearest'):\n",
    "        return transform._warps_cy._warp_fast(img, tf.params, output_shape=output_shape, mode=mode)\n",
    "    \n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(TransIterator, self).transform(Xb, yb)\n",
    "        \n",
    "        Xb_aug = np.empty(shape = (Xb.shape[0], 1, 32, 32), dtype = 'float32')\n",
    "        yb_aug = yb\n",
    "\n",
    "        # random rotations betweein -5 and 5 degrees\n",
    "        dorotate = randint(-5,5)\n",
    "\n",
    "        # random translations\n",
    "        trans_1 = randint(-3,3)\n",
    "        trans_2 = randint(-3,3)\n",
    "\n",
    "        # random zooms\n",
    "        zoom = uniform(0.8, 1.2)\n",
    "\n",
    "        # shearing\n",
    "        shear_deg = uniform(-10, 10)\n",
    "\n",
    "        # set the transform parameters for skimage.transform.warp\n",
    "        # have to shift to center and then shift back after transformation otherwise\n",
    "        # rotations will make image go out of frame\n",
    "        center_shift   = np.array((32, 32)) / 2. - 0.5\n",
    "        tform_center   = transform.SimilarityTransform(translation=-center_shift)\n",
    "        tform_uncenter = transform.SimilarityTransform(translation=center_shift)\n",
    "\n",
    "        tform_aug = transform.AffineTransform(rotation = np.deg2rad(dorotate),\n",
    "                                              scale =(1/zoom, 1/zoom),\n",
    "                                              shear = np.deg2rad(shear_deg),\n",
    "                                              translation = (trans_1, trans_2))\n",
    "\n",
    "        tform = tform_center + tform_aug + tform_uncenter\n",
    "        \n",
    "        for j in range(Xb.shape[0]):\n",
    "            Xb_aug[j][0] = self.fast_warp(Xb[j][0], tform,\n",
    "                                          output_shape = (32, 32))\n",
    "\n",
    "        return Xb_aug, yb_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting nn \n",
    "net = NeuralNet(\n",
    "    layers = [\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('dropout4', layers.DropoutLayer),\n",
    "        ('conv5', layers.Conv2DLayer),\n",
    "        ('conv6', layers.Conv2DLayer),\n",
    "        ('pool7', layers.MaxPool2DLayer),\n",
    "        ('dropout8', layers.DropoutLayer),\n",
    "        ('conv9', layers.Conv2DLayer),\n",
    "        ('conv10', layers.Conv2DLayer),\n",
    "        ('dropout12', layers.DropoutLayer),\n",
    "        ('hidden13', layers.DenseLayer),\n",
    "        ('dropout14', layers.DropoutLayer),\n",
    "        ('hidden15', layers.DenseLayer),\n",
    "        ('dropout16', layers.DropoutLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "    ],\n",
    "\n",
    "    input_shape = (None, 1, 32, 32),\n",
    "    conv1_num_filters = 128, conv1_filter_size = (3, 3),\n",
    "    conv2_num_filters = 128, conv2_filter_size = (3, 3),\n",
    "    pool3_pool_size = (2, 2),\n",
    "    dropout4_p = 0,\n",
    "    conv5_num_filters = 256, conv5_filter_size = (3, 3),\n",
    "    conv6_num_filters = 256, conv6_filter_size = (3, 3),\n",
    "    pool7_pool_size = (2, 2),\n",
    "    dropout8_p = 0.2,\n",
    "    conv9_num_filters = 512, conv9_filter_size = (3, 3),\n",
    "    conv10_num_filters = 512, conv10_filter_size = (3, 3),\n",
    "    dropout12_p = 0.2,\n",
    "    hidden13_num_units = 1024,\n",
    "    dropout14_p = 0.5,\n",
    "    hidden15_num_units = 1024,\n",
    "    dropout16_p = 0.5,\n",
    "    output_num_units = 62, output_nonlinearity = softmax,\n",
    "\n",
    "    batch_iterator_train = TransIterator(batch_size = 2500),\n",
    "    batch_iterator_test = BatchIterator(batch_size = 2500),\n",
    "\n",
    "    update = updates.adam,\n",
    "\n",
    "    use_label_encoder = True,\n",
    "    regression = False,\n",
    "    max_epochs = 300,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parameters to layer 'conv1' (shape 128x1x3x3).\n",
      "Loaded parameters to layer 'conv1' (shape 128).\n",
      "Loaded parameters to layer 'conv2' (shape 128x128x3x3).\n",
      "Loaded parameters to layer 'conv2' (shape 128).\n",
      "Loaded parameters to layer 'conv5' (shape 256x128x3x3).\n",
      "Loaded parameters to layer 'conv5' (shape 256).\n",
      "Loaded parameters to layer 'conv6' (shape 256x256x3x3).\n",
      "Loaded parameters to layer 'conv6' (shape 256).\n",
      "Loaded parameters to layer 'conv9' (shape 512x256x3x3).\n",
      "Loaded parameters to layer 'conv9' (shape 512).\n",
      "Loaded parameters to layer 'conv10' (shape 512x512x3x3).\n",
      "Loaded parameters to layer 'conv10' (shape 512).\n",
      "Loaded parameters to layer 'hidden13' (shape 512x1024).\n",
      "Loaded parameters to layer 'hidden13' (shape 1024).\n",
      "Loaded parameters to layer 'hidden15' (shape 1024x1024).\n",
      "Loaded parameters to layer 'hidden15' (shape 1024).\n",
      "Loaded parameters to layer 'output' (shape 1024x62).\n",
      "Loaded parameters to layer 'output' (shape 62).\n",
      "# Neural Network with 6212542 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  ---------  ---------\n",
      "  0  input      1x32x32\n",
      "  1  conv1      128x30x30\n",
      "  2  conv2      128x28x28\n",
      "  3  pool3      128x14x14\n",
      "  4  dropout4   128x14x14\n",
      "  5  conv5      256x12x12\n",
      "  6  conv6      256x10x10\n",
      "  7  pool7      256x5x5\n",
      "  8  dropout8   256x5x5\n",
      "  9  conv9      512x3x3\n",
      " 10  conv10     512x1x1\n",
      " 11  dropout12  512x1x1\n",
      " 12  hidden13   1024\n",
      " 13  dropout14  1024\n",
      " 14  hidden15   1024\n",
      " 15  dropout16  1024\n",
      " 16  output     62\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m0.44351\u001b[0m       \u001b[32m1.03218\u001b[0m      0.42968      0.76726  11.34s\n",
      "      2       0.63719       1.11852      0.56967      0.74639  11.26s\n",
      "      3       0.53203       \u001b[32m1.02110\u001b[0m      0.52103      0.77849  11.32s\n",
      "      4       \u001b[36m0.39569\u001b[0m       1.06443      0.37174      0.78732  12.08s\n",
      "      5       0.48686       \u001b[32m1.00733\u001b[0m      0.48331      0.79213  11.99s\n",
      "      6       0.40215       \u001b[32m0.95121\u001b[0m      0.42278      0.80658  11.76s\n",
      "      7       \u001b[36m0.28871\u001b[0m       0.96496      0.29920      0.79374  11.82s\n",
      "      8       0.36396       0.99789      0.36473      0.78090  11.76s\n",
      "      9       \u001b[36m0.28748\u001b[0m       0.97475      0.29493      0.78732  11.73s\n",
      "     10       \u001b[36m0.23234\u001b[0m       0.96681      0.24032      0.79695  11.72s\n",
      "     11       0.26309       0.97020      0.27117      0.79695  11.76s\n",
      "     12       0.56876       1.03779      0.54804      0.77929  11.71s\n",
      "     13       0.43985       1.00619      0.43714      0.78973  11.67s\n",
      "     14       0.46904       0.99340      0.47215      0.77929  11.67s\n",
      "     15       0.56902       0.97598      0.58303      0.78170  11.70s\n",
      "     16       0.36982       1.00153      0.36925      0.78812  11.67s\n",
      "     17       0.32597       1.01795      0.32022      0.78973  11.67s\n",
      "     18       0.27689       0.97637      0.28359      0.79454  11.66s\n",
      "     19       \u001b[36m0.21021\u001b[0m       0.98973      0.21239      0.79374  11.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuda/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:417: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "# train nn\n",
    "net.load_params_from(os.path.join(model_root, 'recog_for_icdar.pkl')); # or load a pretrained model!\n",
    "net.fit(data_train_x, data_train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78936605317\n"
     ]
    }
   ],
   "source": [
    "pred = net.predict(data_test_x)\n",
    "print accuracy_score(data_test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.11      0.17        46\n",
      "          1       0.75      0.65      0.70        46\n",
      "          2       0.92      0.96      0.94        49\n",
      "          3       0.86      0.71      0.77        17\n",
      "          4       1.00      0.29      0.45        24\n",
      "          5       0.56      0.48      0.52        29\n",
      "          6       1.00      0.60      0.75        15\n",
      "          7       0.60      0.30      0.40        10\n",
      "          8       0.43      0.50      0.46         6\n",
      "          9       1.00      0.27      0.42        15\n",
      "          A       0.93      0.87      0.90       223\n",
      "          B       0.61      0.83      0.70        47\n",
      "          C       0.86      0.82      0.84       153\n",
      "          D       0.85      0.76      0.80        74\n",
      "          E       0.82      0.93      0.87       322\n",
      "          F       0.83      0.89      0.86        76\n",
      "          G       0.87      0.92      0.89        63\n",
      "          H       0.95      0.85      0.90        97\n",
      "          I       0.59      0.39      0.47       163\n",
      "          J       0.45      0.38      0.42        13\n",
      "          K       0.97      0.61      0.75        46\n",
      "          L       0.87      0.82      0.85       131\n",
      "          M       0.69      0.87      0.77        89\n",
      "          N       0.98      0.85      0.91       153\n",
      "          O       0.65      0.59      0.62       187\n",
      "          P       0.88      0.86      0.87        91\n",
      "          Q       0.00      0.00      0.00         4\n",
      "          R       0.88      0.86      0.87       205\n",
      "          S       0.82      0.85      0.83       229\n",
      "          T       0.83      0.84      0.84       205\n",
      "          U       0.84      0.75      0.79        92\n",
      "          V       0.94      0.65      0.77        26\n",
      "          W       0.86      0.79      0.83        39\n",
      "          X       0.93      0.68      0.79        19\n",
      "          Y       0.79      0.90      0.84        42\n",
      "          Z       0.00      0.00      0.00         7\n",
      "          a       0.83      0.85      0.84       171\n",
      "          b       0.53      0.83      0.65        24\n",
      "          c       0.78      0.69      0.73       100\n",
      "          d       0.84      0.80      0.82        54\n",
      "          e       0.90      0.89      0.90       331\n",
      "          f       0.92      0.77      0.84        47\n",
      "          g       0.63      0.76      0.69        38\n",
      "          h       0.90      0.77      0.83        86\n",
      "          i       0.76      0.84      0.80       182\n",
      "          j       0.00      0.00      0.00         4\n",
      "          k       0.58      0.85      0.69        33\n",
      "          l       0.31      0.42      0.36       105\n",
      "          m       0.81      0.82      0.82        51\n",
      "          n       0.86      0.90      0.88       162\n",
      "          o       0.59      0.76      0.66       194\n",
      "          p       0.74      0.75      0.74        56\n",
      "          q       0.00      0.00      0.00         3\n",
      "          r       0.89      0.82      0.86       177\n",
      "          s       0.79      0.86      0.82       154\n",
      "          t       0.78      0.89      0.83       173\n",
      "          u       0.64      0.81      0.71        67\n",
      "          v       0.53      0.71      0.61        24\n",
      "          w       0.68      0.79      0.73        19\n",
      "          x       0.48      0.92      0.63        12\n",
      "          y       0.86      0.75      0.80        57\n",
      "          z       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.80      0.79      0.79      5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(data_test_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.save_params_to(os.path.join(model_root, 'recog_for_icdar.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
